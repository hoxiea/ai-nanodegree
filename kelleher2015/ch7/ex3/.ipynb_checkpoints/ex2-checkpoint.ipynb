{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kelleher 2015, Chapter 7, Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we're going to explore using gradient descent to fit a multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the training data AND the new data\n",
    "input_file = \"ex2data.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Separate into features and target\n",
    "target_colname = \"OxyCon\"\n",
    "X = df.drop(target_colname, axis=1)\n",
    "y = df[target_colname]\n",
    "\n",
    "# Add a 1, for intercept weight purposes\n",
    "X[\"Int\"] = 1\n",
    "X = X[[\"Int\", \"Age\", \"HR\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a) Prediction, Given Weights\n",
    "\n",
    "Make a prediction for each observation, given some weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.15,  26.  ,  25.55,  13.4 ,   8.9 ,  20.9 ,  28.85,  19.4 ,\n",
       "        17.75,  29.6 ,  19.85,  16.85])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.array([-59.50, -0.15, 0.60])\n",
    "yhat = np.dot(X, weights)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b) Sum of Squared Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4035.1863000000026"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((yhat - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c) Gradient Descrent Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-59.49956706,  -0.13174326,   0.6       ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.000002\n",
    "weights2 = np.copy(weights)\n",
    "for j in range(2):\n",
    "    weights2[j] = weights2[j] + alpha * np.sum((y - yhat) * X.iloc[:, j])\n",
    "weights2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d) Sum of Squared Errors, New Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3708.913137307014"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat2 = np.dot(X, weights2)\n",
    "np.sum((yhat2 - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray, our SSE has decreased after an iteration of gradient descrent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
